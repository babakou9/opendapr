---
title: "Advanced use of `get_url()`"
author: "Paul Taconet"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Advanced use of the function get_url}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
NOT_CRAN <- identical(tolower(Sys.getenv("NOT_CRAN")), "true") # vignette will not be executed when tested on the cran
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  message = FALSE,
  warning = FALSE,
  purl = NOT_CRAN
)
```

```{r setup, message=F}
require(opendapr)
require(sf)
require(purrr)
```

In the `vignette("simple_workflow")`, we have imported data : 

* from several collections (MOD11A1.006, GPM_L3/GPM_3IMERGDF.06, SMAP/SPL3SMP_E.003) ;
* over one single region of interest (ROI) ;
* for one single time frame of interest (2017-01-01 to 2017-01-30).

So far so good, but what if we need ***multiple regions of interest***, and / or ***multiple time frames of interest*** ? Those case are likely to happen, for instance : 

* multiple time frames of interest : we have spatiotemporal sampling data - e.g. species occurence - that were collected over a large time frame and we want to study how local past environmental / climatic conditions influence the occurence ;
* multiple regions of interest : we want to compare two areas in terms of their environmental or climatic conditions.

We could use `for` loops or related stuff to do the job. However, this would not be very optimized. In this vignette, we explain why and we show how to optimize the data import in those cases. Let's start ! 

First of all login to EOSDIS Earthdata

```{r example_prepare, eval=NOT_CRAN}
# Login to Earthdata servers with username and password. To create an account go to : https://urs.earthdata.nasa.gov/.
username <- Sys.getenv("earthdata_un")
password <- Sys.getenv("earthdata_pw")
log <- login(credentials = c(username,password), source = "earthdata")
```

## Import data over multiple regions of interest

The `get_url()` function internally supports the import of multiple regions of interest : the `roi` argument (which must be a POLYGON-type geometry `sf` or `sfc` object) can be composed of several features. 

As an example :

```{r, eval=NOT_CRAN }
# This ROI is composed of two features :
(roi <- st_as_sf(data.frame(name=c("Korhogo","Diebougou"),geom=c("POLYGON ((-5.82 9.54, -5.42 9.55, -5.41 8.84, -5.81 8.84, -5.82 9.54))",
                                   "POLYGON ((-3.62 11.03, -3.13 11.04, -3.11 10.60, -3.60 10.60, -3.62 11.03))"
                                   )),wkt="geom",crs = 4326))
```

```{r, echo=F, fig.height=5, fig.width=3, eval=NOT_CRAN }
require(mapview)
mapview::mapview(roi,legend=F)
```

Get the urls for MOD11A1.006, GPM_L3/GPM_3IMERGDF.06 and SMAP/SPL3SMP_E.003 collections for these 2 regions of interest and the time frame : 

```{r get_url, eval=NOT_CRAN}
time_range <- as.Date(c("2017-01-01","2017-01-30"))

## Get the URLs of MODIS Terra LST daily
urls_mod11a1 <- get_url(
  collection = "MOD11A1.006",
  variables = c("LST_Day_1km","LST_Night_1km","QC_Day","QC_Night"),
  roi = roi,
  time_range = time_range
 )

## Get the URLs of GPM daily
urls_gpm <- get_url(
  collection = "GPM_L3/GPM_3IMERGDF.06",
  variables = c("precipitationCal","precipitationCal_cnt"),
  roi = roi,
  time_range = time_range
 )

## Get the URLs of SMAP 3-days
urls_smap <- get_url(
  collection = "SMAP/SPL3SMP_E.003",
  variables = c("Soil_Moisture_Retrieval_Data_AM_soil_moisture","Soil_Moisture_Retrieval_Data_AM_retrieval_qual_flag","Soil_Moisture_Retrieval_Data_PM_soil_moisture_pm","Soil_Moisture_Retrieval_Data_PM_retrieval_qual_flag_pm"),
  roi = roi,
  time_range = time_range
 )

head(urls_mod11a1,3)

head(urls_gpm,3)

head(urls_smap,3)
```

We notice that in the 'name' and 'destfile' fields, we now have a '_1' and '_2' at the end of the name / destfile which correspond to the two features of the object `roi`.

We can now download data as usual with `download_data()` ! 

<!--
```{r download_data, eval=NOT_CRAN }
df_to_dl <- rbind(urls_mod11a1,urls_gpm,urls_smap)
res_dl <- download_data(df_to_dl,source="earthdata",parallel = TRUE)

print(str(res_dl))
```

-->

## Import data over multiple time frames of interest

Of course, we could loop over the `get_url()` with the time ranges of interest, and get the data. However, the `get_url()` function does query the OPeNDAP servers each time it is called. This query internally imports various data, including OPeNDAP time, latitude and longitude vectors, and this process takes some time. In case you loop over the function for the same ROI and multiple time frames of interest, it will import again and again the same data, which is quite useless.

Here is where the function `get_optional_parameters()` comes into the game. For a given collection and ROI, this function queries the OPeNDAP server and retrieves the information that we were mentionning in the previous paragraph. This function is actually run within the `get_url()` function, but its output can also be provided as input parameter `opt_param` of `get_url()`. If `get_url()` is queried multiple times for the same couple {collection, ROI}, it is hence more efficient to pre-compute only once the argument `opt_param` using `get_optional_parameters()` and to further provide it to `get_url()` within a `for` loop or e.g. a `purrr::map()` function.

So when we have multiple time frames of interest, prior to executing `get_url()` we retrieve the `opt_param` parameter for each collection and roi with `get_optional_parameters()` :

```{r multiple_timeframes, eval=NOT_CRAN }
# We use the ROI defined above and we get the opt_param for each collection
opt_param_mod11a1 <- get_optional_parameters("MOD11A1.006",roi)
opt_param_gpm <- get_optional_parameters("GPM_L3/GPM_3IMERGDF.06",roi)
opt_param_smap <- get_optional_parameters("SMAP/SPL3SMP_E.003",roi)
```

Next we define our time frames of interest (here, for the example, january of each year from 2016 to 2019) : 

```{r set_multiple_timeframes, eval=NOT_CRAN }
time_ranges <- list(as.Date(c("2016-01-01","2016-01-31")),
                    as.Date(c("2017-01-01","2017-01-31")),
                    as.Date(c("2018-01-01","2018-01-31")),
                    as.Date(c("2019-01-01","2019-01-31")))
```

And we finally get our URLs, using a for loop or a `purrr::map()` function over our time frames of interest and setting the `opt_param` parameter in `get_url()`  : 

```{r get_url_multiple_timeframes, eval=NOT_CRAN}
# initialization
urls_mod11a1 <- NULL
urls_gpm <- NULL
urls_smap <- NULL

# for loop to get the url for each time range of interest. 
for (i in 1:length(time_ranges)){

  urls_mod11a1 <- rbind(urls_mod11a1,
                      get_url(
                        collection = "MOD11A1.006",
                        variables = c("LST_Day_1km","LST_Night_1km","QC_Day","QC_Night"),
                        roi = roi,
                        time_range = time_ranges[[i]],
                        opt_param = opt_param_mod11a1) # note the presence of the argument 'opt_param'  
                      )

  urls_gpm <- rbind(urls_gpm,
                  get_url(
                    collection = "GPM_L3/GPM_3IMERGDF.06",
                    variables = c("precipitationCal","precipitationCal_cnt"),
                    roi = roi,
                    time_range = time_ranges[[i]],
                    opt_param = opt_param_gpm)
                  )

  urls_smap <- rbind(urls_smap,
                  get_url(
                    collection = "SMAP/SPL3SMP_E.003",
                    variables = c("Soil_Moisture_Retrieval_Data_AM_soil_moisture","Soil_Moisture_Retrieval_Data_AM_retrieval_qual_flag","Soil_Moisture_Retrieval_Data_PM_soil_moisture_pm","Soil_Moisture_Retrieval_Data_PM_retrieval_qual_flag_pm"),
                    roi = roi,
                    time_range = time_ranges[[i]],
                    opt_param = opt_param_smap)
                  )

}

nrow(urls_mod11a1)
head(urls_mod11a1,3)

nrow(urls_gpm)
head(urls_gpm,3)

nrow(urls_smap)
head(urls_smap,3)
```

```{r get_url_multiple_timeframes_purr, eval=NOT_CRAN}
### Note : we could have done the same thing more elegantly using purrr::map(), e.g.  : 
#urls_mod11a1 <- map_dfr(.x = time_ranges, ~get_url(
#  collection = "MOD11A1.006",
#  variables = c("LST_Day_1km","LST_Night_1km","QC_Day","QC_Night"),
#  roi = roi,
#  time_range = .x,
#  opt_param = opt_param_mod11a1)
#  )
```

If we want to be convinced that this way of doing the things is quicker than not providing the `opt_param` parameter : 

```{r compare, eval=NOT_CRAN}
require(tictoc)

# Not providing the `opt_param` parameter
tic()
for (i in 1:length(time_ranges)){
  urls_mod11a1_notprov <- rbind(urls_mod11a1,
                      get_url(
                        collection = "MOD11A1.006",
                        variables = c("LST_Day_1km","LST_Night_1km","QC_Day","QC_Night"),
                        roi = roi,
                        time_range = time_ranges[[i]])
                      )
}
toc()

# Providing the `opt_param` parameter
tic()
opt_param_mod11a1 <- get_optional_parameters("MOD11A1.006",roi)
for (i in 1:length(time_ranges)){
  urls_mod11a1_prov <- rbind(urls_mod11a1,
                      get_url(
                        collection = "MOD11A1.006",
                        variables = c("LST_Day_1km","LST_Night_1km","QC_Day","QC_Night"),
                        roi = roi,
                        time_range = time_ranges[[i]],
                        opt_param = opt_param_mod11a1)
                      )
}
toc()


identical(urls_mod11a1_notprov,urls_mod11a1_prov)
```
